% !TeX root = ./mfog-ieee.tex
% \documentclass{article}
% \documentclass[conference]{lib/IEEEtran}
\documentclass[conference]{IEEEtran}
\usepackage{babel}
\usepackage[utf8]{inputenc}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{xspace}
% \usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
% \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%     T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{hyperref}

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcounter{todocounter}

\hypersetup{colorlinks=true, allcolors=black}
\begin{document}

\title{IoT Data Stream Novelty Detection:
Design, Implementation and Evaluation [DRAFT]\thanks{CNPq}}

\author{
  \IEEEauthorblockN{Luís Puhl, Guilherme Weigert Cassales, Hermes Senger, Helio Crestana Guardia}
  \IEEEauthorblockA{Universidade Federal de São Carlos, Brasil \\
    Email: \{luispuhl, gwcassales\}@gmail.com, \{hermes@, helio@dc.\}ufscar.br
  }
  % \IEEEauthorblockN{Hermes Senger}\IEEEauthorblockA{\textit{Universidade Federal de São Carlos}, Brasil \\hermes@ufscar.br}\and
    % \IEEEauthorblockN{Guilherme Weigert Cassales}\IEEEauthorblockA{\textit{Universidade Federal de São Carlos}, Brasil \\gwcassales@gmail.com}
    % \and
    % \IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
    % \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
    % \textit{name of organization (of Aff.)}\\
    % City, Country \\
    % email address or ORCID}
}

\maketitle

\newcommand{\toreview}{}

\ifx\toreview\undefined
  \newcommandx{\nota}[2][1=]{}
  \newcommand{\hl}[1]{}

  \newcommandx{\notahl}[2][1=]{}
  \newcommand{\hlhl}[1]{}
  \newcommandx{\notake}[2][1=]{}
  \newcommand{\hlke}[1]{}
  \newcommandx{\notafa}[2][1=]{}
  \newcommand{\hlfa}[1]{}
\else
  % \newcommandx{\nota}[2][1=]{
  %   \stepcounter{todocounter}
  %   \todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{[\thetodocounter] #2}}
  \newcommand{\hl}[1]{\colorbox{red!25}{#1}}

  % \newcommandx{\notahl}[2][1=]{\stepcounter{todocounter}\todo[
  %   linecolor=green,
  %   backgroundcolor=green!25,
  %   bordercolor=green,#1]{[Helio \thetodocounter] #2}}
  % \newcommand{\hlhl}[1]{\colorbox{green}{#1}}

  % \usepackage{cancel}
  % \newcommandx{\notake}[2][1=]{\stepcounter{todocounter}\todo[
  %   linecolor=yellow,
  %   backgroundcolor=yellow!25,
  %   bordercolor=yellow,#1]{[Kelton \thetodocounter] #2}}
  % \newcommand{\hlke}[1]{\colorbox{yellow}{#1}}

  % \newcommandx{\notafa}[2][1=]{\stepcounter{todocounter}\todo[
  %   linecolor=blue,
  %   backgroundcolor=blue!25,
  %   bordercolor=blue,#1]{[Faria \thetodocounter] #2}}
  % \newcommand{\hlfa}[1]{\colorbox{blue!30}{#1}}

  % \usepackage[showframe,layoutvoffset=0mm,includeall,tmargin=15mm,bmargin=20mm]{geometry}
  % \marginparwidth=34mm
  % \hoffset=-25mm
  % \textwidth=165mm
\fi

\begin{abstract}
  The implementation of the Internet of Things (IoT) is sharply increasing the small
  devices count and variety on edge networks and, following this increase the
  attack opportunities for hostile agents also increases, requiring more from
  the network administrator role and the need for tools to detect and react to those
  threats.
  % 
  One such tool are the Network Intrusion Detection Systems (NIDS) where the network
  traffic is captured and analysed raising alarms when a known attack pattern or
  new pattern is detected.
  For a network security tool to operate in the context of edge and
  IoT it has to comply with processing time, storage space and energy
  requirements alongside traditional requirements for stream and network
  analysis like accuracy and scalability.
  % 
  This work addresses the construction details and evaluation of an prototype
  distributed IDS using MINAS Novelty Detection algorithm
  following up the previously defined IDSA-IoT architecture.
  We discuss the algorithm steps, how it can be deployed in a distributed environment,
  the impacts on the accuracy of MINAS and evaluate the performance and scalability
  using a cluster of constrained devices commonly found in IoT scenarios.
  % 
  We found an increase of \textit{A 0.0} processed network flow descriptors per core
  added to the cluster. Also \textit{B 0.0\%} and \textit{C 0.0\%} change in
  \textit{F1Score} in the tested datasets when stream was unlimited in speed and
  limited to \textit{0.0 z MB/s} respectively.
\end{abstract}

\begin{IEEEkeywords}
% Detecção de Novidades, Detecção de Intrusão, Fluxos de Dados, Computação Distribuı́da, Computação em Névoa, Internet das Coisas.
novelty detection, intrusion detection, data streams, distributed system, edge computing, internet of things
\end{IEEEkeywords}

\section{Introduction}

% skel
  % The implementation of the Internet of Things (IoT) is sharply increasing the small
  % devices count and variety on edge networks and, following this increase the
  % attack opportunities for hostile agents also increases, requiring more from
  % the network administrator role and the need for tools to detect and react to those
  % threats.
  % % 
  % One such tool are the Intrusion Detection Systems (IDS) where the network
  % traffic is captured and analysed raising alarms when a known attack pattern or
  % new pattern is detected.
  % To build an IDS one option for base algorithm are
  % the Data Stream Novelty Detection being MINAS one of those.
  % % 
  % Furthermore, for a network security tool to operate in the context of edge and
  % IoT it has to comply with processing time, storage space and energy
  % requirements alongside traditional requirements for stream and network
  % analysis like accuracy and scalability.
  % % 
  % This work addresses the construction details and evaluation of an prototype
  % distributed IDS using MINAS Novelty Detection algorithm
  % following up the previously defined IDSA-IoT architecture.
  % We discuss the algorithm steps, how it can be deployed in a distributed environment,
  % the impacts on the accuracy of MINAS and evaluate the performance and scalability
  % using a cluster of constrained devices commonly found in IoT scenarios.
  % % 
  % We found an increase of \textit{A 0.0} processed network flow descriptors per core
  % added to the cluster. Also \textit{B 0.0\%} and \textit{C 0.0\%} change in
  % \textit{F1Score} in the tested datasets when stream was unlimited in speed and
  % limited to \textit{0.0 z MB/s} respectively.

\newcommand{\refminas}{\textit{Ref}\xspace}
\newcommand{\mfog}{\textit{MFOG}\xspace}
\newcommand{\iot}{IoT\xspace}

The advent of Internet of Things (\iot) is growing the count and diversity of
devices on edge networks, this growth increases network traffic patterns and
extends opportunities for cyber attacks presenting new challenges for network
administrators.
To address those challenges new Network Intrusion Detection Systems (NIDS) and
architectures can be explored, especially in Fog Computing and Data Stream (DS)
areas.

% Data Stream (DS)

% - Desafio, resposta, justificativa.
% - Artigo para setembro ou outubro.
% - Revisão dos valores da avaliação.

% ### Desafios, Respostas e Justificativas

% Desafios de arquitetura e validação:

% - Construção de um protótipo da arquitetura IDSA-IoT:
%   - Kafka (Python): Distribuição e balanceamento pelo cluster kafka, hipótese refutada.
%   - Flink (Java ou Scala): Execução do cluster nos dispositivos de névoa, hipótese refutada.
%   - MPI (C e Python): Execução do cluster nos dispositivos de névoa, hipótese aceita.
% - Reimplementação do algoritmo MINAS com fidelidade:
%   - Duas versões: a descrita e a implementação de referência (em Java).
%   - Resolução: utilizar a descrição, não *seguir* a imp. referência, apenas como ponto de comparação. Exemplos:
%     - Definição de raio `r = f * σ` (fator vezes desvio padrão) para `r = max(distance)` (distância máxima);
%     - Tamanho do buffer de desconhecidos e frequência de execução do passo de detecção de novidade;

Expected results:
A system that embraces and explores the inherent distribution of fog computing
in a IoT scenario opposing regular systems where data streams are collected and
centralized before processing;
Impact assessment of the impact of distributed, regional flow characteristics,
local vs global vs distributed forgetting mechanism and other polices.

IDS characteristics and description of physical scenario.

MINAS characteristics.

Distribution and IDSA-IoT architecture.

This paper is structured as follows:
Section \ref{sec:related} presents previous works that addresses related
problems and how they influenced our solution.
Section \ref{sec:implementation} address our proposal, the work done, issues
found during implementation and discusses parameters and configurations options
and how we arrived at our choices.
Section \ref{sec:experiments} shows experiments layouts and results, we
compare serial and distributed implementation's metrics for validation,
we also evaluate communication delay effects on classification metrics and
conclude with the speedup per core and overall maximum stream speed.
Section \ref{sec:conclusion} summarizes the research results and presents our
final conclusions and future works.


% ----------------------------------------------------------------------------------------------------------------------
\section{Related Work}\label{sec:related}

Recent works explored those areas, to name a few: BigFlow \cite{Viegas2019}
employing Apache Kafka and Apache Flink for distributed stream processing
evaluating with package stream dataset,
CATRACA \cite{Lopez2018,AndreoniLopez2019a} uses 
Apache Kafka and Apache Spark for stream processing and 

% ----------------------------------------------------------------------------------------------------------------------
% - Escrever! Corpo:
%   - Proposal (retomar problema {iot, sec, ND}, objetivo, soluções {minas, paralelismo, distribuído, ~~py-kafka, flink,~~ mpi}, propor uma solução)
%   - Implementation (mpi, c, data-structures, data-flow, )
%   - Experiments (rpi, cluster, `evaluate.py`)
%   - Results
%   - Conclusion
% - Demonstrar o paralelismo com figura de pipeline (time vs instruction)

\section{Proposal}\label{sec:prop}
% Proposal:
%  - retomar problema {iot, sec, ND};
%  - objetivo;
%  - soluções {minas, paralelismo, distribuído, ~~py-kafka, flink,~~ mpi}
%  - propor uma solução


Fog computing infrastructure aims to offload
computing resources from cloud providers by placing edge
devices closer to end-users and/or data sources.

Objective: Distributed novelty detection in streams using limited hardware.

Previous attempts to attain the objective of distributed fast 

\section{Implementation}\label{sec:implementation}

The original MINAS algorithm has a companion implementation (\refminas)
written in Java using MOA library base algorithms such as K-means and CluStream.
\refminas employs Java's double, a $64 bits$ number whose precision is not
absolutely necessary and, as it is often necessary to shuffle between nodes via
network and a small economy could be made with only a float number with $32 bits$.
Another difference between \refminas and \mfog is cluster radius calculation
from the distances of elements forming the cluster and the cluster's center,
where the former uses the maximum distance, the latter uses the standard deviation
of all distances as described in \cite{Faria2016minas}.

\begin{figure}[htb]
\centerline{\includegraphics[width=0.5\textwidth]{figures/mfog-arch-v2_en.png}}
\caption{\mfog architecture overview.}
\label{fig:mfog-architecture}
\end{figure}

% Desafios de implementação:
% <!--
% - Definição de raio: desvio padrão das distâncias versus distancia máxima;
% - Atualização do micro-cluster limita-se à atualização do atributo \texttt{T};
% - Remoção de exemplos na implementação de referência é feita somente para o algoritmo \textit{CluStream};
% - Inclusão de borda: algoritmo inclui ($<=$), referência não inclui ($<$);
% - Seguiu-se as mesmas divergências anteriores para comparação dos resultados com a implementação referência;
% - Inclusão da borda;
% - Comportamento do mecânismo de \textit{sleep-model} não está definido, portanto não está ativo;
% - Processo de clusterização é limitado ao algoritmo \textit{K-Means}. Algoritmo \textit{CluStream} não está implementado;
% - -->
% - `Double vs Float`:
%   - Na implementação de referência, java double é utilizado;
%   - Na nova implementação duas versões foram testadas e a diferença de precisão entre as duas é de `5 E-8`;
%   - **Solução:** Use `float32` e economize os bits já que haverá comunicação entre nós e módulos;
% - Formato do fluxo de saída:
%   - Implementação de referência utiliza a tripla `(id, classe, etiqueta)`;
%   - Primeira implementação em C utiliza `(id, clusterLabel, clusterId, clusterRadius, label, distance, secondDistance)`;
%   - Segunda implementação utiliza dupla `(id, label)`;
%   - Na etapa de avaliação, independente de versão, o fluxo original é lido;
%   - **Solução:** O formato mínimo é `(id, label)`;

The stream format for input and output also of note.
Input information needed is the value of the item, this value is a number
sequence of length $d$ (referenced as dimension).
In addition to the value for evaluation and training purposes the class
identifier as single character, optimality an unique item identifier
(\textit{uid}) can be provided.
For output information and format the decision isn't so clear as we can't
predict future system integrations needs like only novelty alarms or every
item's original value with assigned label so, we have a compromise and put only
enough information for the Evaluation Module (where the full information
from the testing file or stream can de accessed) meaning the format can be
defined as a tuple containing \textit{uid} and assigned label.

% - Reprocessamento dos exemplos utilizados para atualização do modelo:
%   - Muda o comportamento do operador de fluxo de `Map` para `Flatmap`, ou seja,
%     requer outro fluxo de saída para a transmissão de padrões novidade (alarmes);
%   - Para reclassificação a definição de raio é modificada de `r = f * σ` (fator
%     multiplicando desvio padrão) para `r = max(distance)` (distância máxima);
%   - Passível da crítica de *overfitting*. Isto é, este processo pode
%     inflar a métrica de precisão;
%   - **Solução:** *em aberto*;

\hl{Adicionar fig arch fisica.}

Another implementation decision related to the output stream is whether or not
to reprocess, and add to the output stream, examples in the unknown buffer after
the novelty detection procedure, meaning one item can be classified once as
unknown and again with a label.
Our tests using this technique had increased true positives when compared to
not using it.
However this changes the stream operator behavior from a \textit{Map} to a
\textit{FlatMap} having duplicate entries on the output stream as previously
mentioned.
Regardless of choice the classification of the unknown buffer after a model
update, using the full model or just the added set of clusters, is done to
remove the examples ``consumed'' in the creation of a new cluster in the internals
of the clustering algorithm.
% This removal can be made less complex if using only new clusters 

% Próximos desafios:
% - Distribuição e paralelização para minimização de latência entre novo item no fluxo e sua classificação:
%   - Tempo de passagem da instância pelo classificador;
%   - Volume máximo do sistema;
%   - Diferenças de precisão de acordo com a carga;


\newcommand{\reffig}[1]{Figure \ref{fig:#1}\xspace}

For \mfog the Message Passing Interface (MPI) library was used.
In MPI programming, multiple processes of the same program are created by the
runtime and each process instance receives a rank parameter, for \mfog this
parameters indicate if the process is root, rank $0$, or leaf otherwise.
Beyond this division, each process also operates two threads, for the root
there is a sampler and detector threads, for the leafs each has a model receiver
thread and multiple classifier threads.
The overall sequence of creation is shown in \reffig{mfog-mpi-life}.

\begin{figure}[htb]
  \centerline{\includegraphics[width=0.5\textwidth]{figures/mfog-arch-mpi.png}}
  \caption{\mfog life line overview.}
  \label{fig:mfog-mpi-life}
\end{figure}

Polices

- Detecção de novidades e manutenção de modelo em ambiente distribuído:

  - Mecanismo de ND local (síncrono) vs nuvem quanto à atraso de definição de modelo
    (nesse ponto é onde a hipótese prevê maior diferença, grande ponto de interesse);

  - Mecanismo de esquecimento local vs global (modelo único ou por nó);

  - Atraso na reclassificação dos desconhecidos;


The Evaluation Module was also build following reference techniques like
multi-class confusion matrix with label-class association
\cite{Faria2016minas}
to extract classification quality metrics.

% ------------------------------------------------------------------------------
\section{Experiments and Results}\label{sec:experiments}

For the experimental setup we dedicated 3 Raspberry Pi single board computers
connected via Gigabit Ethernet Switch forming a simple cluster.
This cluster stored all source code, binaries (compiled and linked in place) and
datasets, being accessed via our laboratory network over Secure Shell (SSH).
All experiments were executed in this cluster for isolation of otherwise unforeseen
variations.

The dataset used is the December 2015 segment of
Kyoto 2006+ Dataset\footnote{Available at \url{http://www.takakura.com/Kyoto_data/}}
(Traffic Data from Kyoto University's Honeypots)
\cite{Song2011}.
This segment was filtered (from $7 865 245$ instances) to only examples
associated to known attack types identified by existing IDS, and attack types
with more than $10 000$ instances for significance as done by \cite{Cassales2019a}.
% , this removes 46,390 instances. TODO: revisar, pois 7M != 700K.
The remaining instantes then were transformed by normalization, transforming
each feature value space (e.g. IP Address, Duration, Service) to the
Real interval $[0, 1]$.
The result is stored in two sets, training set and test set, using the holdout
technique filtering in only normal class resulting in $72 000$ instances for
training set and $653 457$ for test set, containing $206 278$ $N$ (normal) class
and $447 179$ $A$ (attack) class.

% Count per class
%            id
% class        
% A      447179
% N      206278

% \begin{quote}
%   For the experiments, we used the Kyoto 2006+ dataset
%   which contains data collected from 2006 to December 2015.
%   We selected examples from one month, December, 2015. Only the examples of known
%   attack types and known IDS alert code with a minimum of 10,000 occurrences (for
%   significance) were considered. The offline training was performed with 72,000
%   examples (i.e., 10\% of the dataset) using the holdout technique.
%   \cite{Cassales2019a}
% \end{quote}

O que quer testar com os experimentos.
\begin{itemize}
  \item Tese: Mostrar que detecção por novidade e classificação continua viável em fog.
  \item Seria inviável por conta do atraso de distribuição de modelo e,
  \item limitação pelo hardware pequeno.
  \item MFOG: Um Agregador Regional, instalado na FOG, que observa a rede local.
\end{itemize}

Como realizou (cenário, rpi, setup, coleta de métricas).

Quais resultados obteve.

Como interpretar os resultados.

\hl{BEGIN Oritações de leitura das métricas e visualizações.}

\subsection{Metrics and Visualizations}

There are two broad evaluation metrics for each experiment:
a time mesure extracted by using \emph{GNU Time 1.9} and,
a set of qualitative mesures extracted by a python program.
The first metric is straightforward and is the time measure of the full program execution.
The latter metric is not as simple and for its extraction required a
purposely build python program.
This program takes two inputs, the test dataset and the captured output stream,
and outputs the confusion matrix, label-class association,
final quality summary with: Hits (accuracy), Misses (Err), Unknowns (UnkR); and
stream visualization chart with per example instance summary with novelty label markers.

For clarity, it is necessary to detail how to interpret and compare each metric,
as for some it is trivial but others are not so straightforward.

In the confusion matrix $M = m_{ij} \in \mathbb{N} ^{c \times{} l}$,
computed by our evaluation program,
each row denotes one of the datasets original (actual) class
and each column denotes the marked (predicted) label present in the captured output stream.
Thus, each cell $M_{c, l}$ contains the count of examples from the test dataset of class $c$
found in the output stream with the label $l$ assigned by the under evaluation experiment.
For the dataset under use, original classes are \emph{``N''} and \emph{``A''}, and
for the labels we have the training class \emph{``N''}, unknown label \emph{``-''} and
the novelties $i \in \mathbb{N}$.

Added to the original confusion matrix $C$ are the rows \emph{Assigned} and
\emph{Hits}.
The former represents which original class $c$ (or if unknown, \emph{-}) the
label $l$ is assigned to, this is computed by using the original class if
$c = l$ or by associated novelty label to original class as described in
\cite{DeFaria2015} section 4.1.
The latter row, \emph{Hits}, shows the true positive count for each label,
computed by coping the value of the cell $M_{c, l}$ where the label is the same
and the class $c$ is the value in the above \emph{Assigned} row.
The \emph{Hits} row is also used to compute the overall accuracy.

For the metric summary table, six metrics from two sources are displayed.
Three metrics \emph{Hits} \emph{Unknowns} \emph{Misses} represented as ratio of the
captured output stream, extracted from the evaluation python
program, computed as follows:
\emph{Hits} (overall accuracy) is the summation of the homograph row in the
extended confusion matrix;
\emph{Unknowns} is the count of examples in the captured output stream marked
with the unknown label \emph{-};
\emph{Misses} is the count of all examples in the captured output stream marked
with a label distinct from the \emph{Assigned} original class and are not marked
as unknown.
\emph{Time}, \emph{System} and \emph{Elapsed} represented in seconds,
are extracted from \emph{GNU Time}.
\emph{Time} is the amount of CPU seconds expended in user-mode
(indicates time used doing CPU intensive computing, e.g. math);
\emph{System} is the amount of CPU seconds expended in kernel-mode
(for our case it indicates time doing input or output);
\emph{Elapsed} is the real-world (wall clock) elapsed time
(indicates how long another system or person had to wait for the result).
To compare the time metric is simple, the lower time taken, the better.

Lastly, the stream visualization chart shows the summary quality metrics
(\emph{Hits} \emph{Unknowns} \emph{Misses})
computed for each example in the captured output stream.
This summary is computed for each example but it uses the \emph{Assigned} row
computed previously to evaluate \emph{Hits}, other metrics are derived as
described before.
Therefore, horizontal axis (x, domain) plots the index of the example and the
vertical axis (y, image) shows the metric computed until that example index on the captured
output stream.
Adding to the summary metrics, novelty label markers are represented as vertical
lines indicating \emph{when} in the captured output stream a new label first
appeared.
Some of the novelty label markers include the label itself ($l \in \mathbb{N}$)
for reference as if showing every label would turn this feature unreadable due
to overlapping.

\hl{END Oritações de leitura das métricas e visualizações.}

\subsection{Results Discussion}

Four main experiments need detailed discussion:
(a) reference implementation of Minas (\refminas) \cite{Faria2016minas};
(b) new implementation in serial mode;
(c) new implementation in single-node, multi-task mode and
(d) new implementation in multi-node, multi-task mode.
Each experiment uses the adequate binary executable, initial model
(or training set for the reference implementation) and test set
to compute a resulting output stream which is stored for qualitative evaluation.
The summary of all four experiments is shown in Table \ref{tab:exper-summary}.

\begin{table}[h]\begin{center}
  \caption{Experiments Collected Metrics Summary}
  \input{../experiments/rpi/almoco/summary.tex}
  \label{tab:exper-summary}
\end{center}\end{table}

The first two experiments (a and b) comparison does serve as validation for our
implementation, while the latter three (b, c and d) serves as showcase for
the effects of distribution.

\begin{figure*}[tb]
  \centerline{
    \includegraphics[width=0.5\textwidth]{../experiments/rpi/almoco/revised-java.log.png}
    \includegraphics[width=0.5\textwidth]{../experiments/rpi/almoco/online-nd.log.png}
  }
  \caption{Reference (a) and Serial (b) implementation: Stream hits and novelties visualization}
  \label{fig:java-serial}
\end{figure*}

\begin{table*}[htb]\begin{center}
  \caption{Reference implementation: Confusion Matrix and Qualitative Metrics}
  \input{../experiments/rpi/almoco/revised-java.log.tex}
  \label{tab:java-matrix}
\end{center}\end{table*}
\begin{table*}[htb]\begin{center}
  \caption{Serial implementation: Confusion Matrix and Qualitative Metrics}
  \input{../experiments/rpi/almoco/online-nd.log.tex}
  \label{tab:libc-matrix}
\end{center}\end{table*}

\begin{figure*}[tb]
  \centerline{
    \includegraphics[width=0.5\textwidth]{../experiments/rpi/almoco/tmi-base.log.png}
    \includegraphics[width=0.5\textwidth]{../experiments/rpi/almoco/tmi-n12.log.png}
  }
  \caption{Parallel single-node (c) and multi-node (d) modes: Stream hits and novelties visualization}
  \label{fig:cluster}
\end{figure*}

\begin{table}[htb]\begin{center}
  \caption{Reference implementation: Confusion Matrix and Qualitative Metrics}
  \input{../experiments/rpi/almoco/tmi-base.log.tex}
  \label{tab:java-matrix}
\end{center}\end{table}
\begin{table}[htb]\begin{center}
  \caption{Serial implementation: Confusion Matrix and Qualitative Metrics}
  \input{../experiments/rpi/almoco/tmi-base.log.tex}
  \label{tab:libc-matrix}
\end{center}\end{table}

% \setcounter{MaxMatrixCols}{20}
% \begin{table*}[htb]
  %   \begin{center}
    %     \caption{Reference implementation: Confusion Matrix and Qualitative Metrics}
    %     \begin{math}\begin{pmatrix}
      %       - & N & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12
%     \end{pmatrix}\end{math}
%     \begin{math}\begin{pmatrix}
%     3774 &  438750 &  123 &  145 &  368 &  8 &  52 &  165 &    1 &  1046 &  161 &  2489 &   71 &  26 \\
%     8206 &  193030 &    0 &   79 &   44 &  0 &   0 &    0 &  229 &   181 &  154 &  4066 &  289 &   0
%     \end{pmatrix}\end{math}
%     \begin{math}\begin{pmatrix}
%       - &       N &    A &    A &    A &  A &   A &    A &    N &     A &    A &     N &    N &   A \\
%       0 &  193030 &  123 &  145 &  368 &  8 &  52 &  165 &  229 &  1046 &  161 &  4066 &  289 &  26 
%     \end{pmatrix}\end{math}
%     \label{math-tab}
%   \end{center}
% \end{table*}

% \begin{figure*}
%   \centering
%   \centerline{
%     \includegraphics[width=0.45\textwidth]{../experiments/revised-java.log.png}
%     \includegraphics[width=0.45\textwidth]{../experiments/revised-java.log.png}
%   }
%   \\
%   \centerline{
%     \includegraphics[width=0.45\textwidth]{../experiments/revised-java.log.png}
%     \includegraphics[width=0.45\textwidth]{../experiments/revised-java.log.png}
%   }
% \label{fig1} 
% \end{figure*}

% ----------------------------------------------------------------------------------------------------------------------
\section{Conclusion}\label{sec:conclusion}

% ----------------------------------------------------------------------------------------------------------------------
\section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without an ``e'' after the ``g''.
% Avoid the stilted expression ``one of us (R. B. G.) thanks $\ldots$''.
% Instead, try ``R. B. G. thanks$\ldots$''.
% Put sponsor  acknowledgments in the unnumbered footnote on the first page.
The authors thank CNPq (Contract 167345/2018-4).
Hermes Senger also thanks CNPq (Contract 305032/2015-1) and FAPESP (Contract
2018/00452-2, and Contract 2015/24461-2) for their support.

% \bibliography{IEEEabrv,refs.bib}
\bibliographystyle{lib/IEEEtran.bst}
\bibliography{refs.bib}
\end{document}
