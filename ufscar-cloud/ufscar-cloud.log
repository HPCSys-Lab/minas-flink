 puhl@gsdr:~$ lxd init
Would you like to use LXD clustering? (yes/no) [default=no]:
Do you want to configure a new storage pool? (yes/no) [default=yes]:
Name of the new storage pool [default=default]:
Name of the storage backend to use (btrfs, dir, lvm) [default=btrfs]:
Create a new BTRFS pool? (yes/no) [default=yes]:
Would you like to use an existing block device? (yes/no) [default=no]:
Size in GB of the new loop device (1GB minimum) [default=15GB]:
Would you like to connect to a MAAS server? (yes/no) [default=no]:
Would you like to create a new local network bridge? (yes/no) [default=yes]:
What should the new bridge be called? [default=lxdbr0]:
What IPv4 address should be used? (CIDR subnet notation, “auto” or “none”) [default=auto]:
What IPv6 address should be used? (CIDR subnet notation, “auto” or “none”) [default=auto]:
Would you like LXD to be available over the network? (yes/no) [default=no]:
Would you like stale cached images to be updated automatically? (yes/no) [default=yes]
Would you like a YAML "lxd init" preseed to be printed? (yes/no) [default=no]: yes
config: {}
networks:
- config:
    ipv4.address: auto
    ipv6.address: auto
  description: ""
  managed: false
  name: lxdbr0
  type: ""
storage_pools:
- config:
    size: 15GB
  description: ""
  name: default
  driver: btrfs
profiles:
- config: {}
  description: ""
  devices:
    eth0:
      name: eth0
      nictype: bridged
      parent: lxdbr0
      type: nic
    root:
      path: /
      pool: default
      type: disk
  name: default
cluster: null

  111  docker-compose exec jobmanager bash
  112  docker-compose exec taskmanager bash
  117  cd flink-project/
  123  docker ps
  124  docker exec f21 bash
  125  docker exec-it f21 bash
  126  docker exec -it f21 bash
  127  docker exec -it f21 bash -c nc -lp 9000
  128  docker exec -it f21 bash -c "nc -lp 9000"
  129  exit
  130  docker run -it hello-flink:v0 bash
  131  docker exec -it f21 bash
  132  docker exec -it f21 tail -f ../log/flink-*-taskexecutor-*.out
  133  docker exec -it f21 bash -c "tail -f ../log/flink-*-taskexecutor-*.out"
  134  docker exec -it f21 bash -c "tals ../log/"
  135  docker exec -it f21 bash -c "ls ../log/"
  136  docker exec -it f21 bash -c "tail -f ../log/flink-*-taskexecutor-*.out"
  137  exit
  138  nc -l 9000
  139  docker-compose ps
  140  docker-compose run --it jobmanager bash
  141  docker-compose exec jobmanager bash
  142  docker-compose down
  143  docker build . --tag hello-flink:v0
  144  docker run hello-flink:v0 bash
  145  docker run -it hello-flink:v0 bash
  146  docker ps
  147  git status
  148  git add dockerfile 
  149  tail history 
  150  history | tail
  151  history
  152  exit
  153  docker
  154  docker build . --tag flink-wordcount:v0
  155  docker help build
  156  docker help run
  157  docker-compose up


puhl@puhl-host:~/minas-flink/udemyexamples$ time java -cp 'target/udemy-examples-1.0-SNAPSHOT.jar:' examples.scala.KMeansVector.KMeansDataSet
real    1m26.552s
user    14m4.338s
sys    4m36.998s

# using ram-temp-fs
real    1m27.328s
user    14m56.892s
sys    3m50.586s
#---
real    1m24.358s
user    14m54.226s
sys    4m7.690s
#---
real    1m25.824s
user    13m30.876s
sys    4m2.530s


# Centers from one10th
## cloud
real    0m39.870s     0m32.963s    0m28.843s
user    4m39.230s     5m3.768s    4m20.933s
sys     5m32.437s     3m7.262s    2m21.765s
## local
69.76s user 3.88s system 447% cpu 16.470 total
73.24s user 4.05s system 456% cpu 16.916 total
69.62s user 4.06s system 442% cpu 16.657 total

# Training kmeans from one10th
## cloud
real    1m36.415s    1m18.697s    1m16.595s
user    20m19.103s   17m6.909s    16m49.352s
sys     9m50.067s    5m9.445s     4m1.866s

## local
748.85s user 8.31s system 696% cpu 1:48.67 total
758.30s user 9.03s system 414% cpu 3:04.92 total
854.89s user 11.36s system 422% cpu 3:24.89 total

40 vs 8

